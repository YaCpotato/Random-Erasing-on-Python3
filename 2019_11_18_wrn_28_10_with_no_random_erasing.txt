[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 5893350356927264149
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 16049300247507951710
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:1"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 16305333363996391014
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:2"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 8303960923542891136
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:3"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 17697924712872946314
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 11453621359440723370
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 14855432090373905428
physical_device_desc: "device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3d:00.0, compute capability: 7.0"
, name: "/device:GPU:1"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 16513883550350347663
physical_device_desc: "device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3e:00.0, compute capability: 7.0"
, name: "/device:GPU:2"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 17713936182083528429
physical_device_desc: "device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b1:00.0, compute capability: 7.0"
, name: "/device:GPU:3"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 14884786539605087043
physical_device_desc: "device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b2:00.0, compute capability: 7.0"
]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 160)  23200       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 160)  0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 160)  230560      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 160)  2720        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 160)  230560      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 32, 32, 160)  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 160)  230560      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 160)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 160)  230560      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 32, 32, 160)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 160)  230560      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 160)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 160)  230560      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 32, 32, 160)  0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 160)  230560      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 160)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  461120      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 16, 16, 320)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 320)  921920      dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 320)  51520       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 320)  921920      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 16, 16, 320)  0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 320)  921920      dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 320)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 320)  921920      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 16, 320)  0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 320)  921920      dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 320)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 320)  921920      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 16, 16, 320)  0           activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 320)  921920      dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 320)  1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 320)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 320)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 320)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 640)    1843840     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 8, 8, 640)    0           activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 640)    205440      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 640)    3687040     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 8, 8, 640)    0           activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 640)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 640)    3687040     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 8, 8, 640)    0           activation_22[0][0]              
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_11[0][0]                 
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 640)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 640)    3687040     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 8, 8, 640)    0           activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 640)    2560        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 640)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 640)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 640)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           6410        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,507,242
Trainable params: 36,489,290
Non-trainable params: 17,952
__________________________________________________________________________________________________
Train on 45000 samples, validate on 5000 samples
Epoch 1/50
 - 78s - loss: 3.0998 - acc: 0.3190 - val_loss: 2.5587 - val_acc: 0.2312
Epoch 2/50
 - 70s - loss: 1.5116 - acc: 0.4813 - val_loss: 1.7457 - val_acc: 0.4244
Epoch 3/50
 - 70s - loss: 1.2677 - acc: 0.5620 - val_loss: 1.7996 - val_acc: 0.4390
Epoch 4/50
 - 70s - loss: 1.0957 - acc: 0.6207 - val_loss: 1.3247 - val_acc: 0.5518
Epoch 5/50
 - 70s - loss: 0.9510 - acc: 0.6664 - val_loss: 1.4276 - val_acc: 0.5342
Epoch 6/50
 - 70s - loss: 0.8440 - acc: 0.7044 - val_loss: 1.3313 - val_acc: 0.5762
Epoch 7/50
 - 70s - loss: 0.7633 - acc: 0.7291 - val_loss: 1.0024 - val_acc: 0.6578
Epoch 8/50
 - 70s - loss: 0.7001 - acc: 0.7575 - val_loss: 1.6295 - val_acc: 0.5322
Epoch 9/50
 - 70s - loss: 0.6426 - acc: 0.7744 - val_loss: 0.9009 - val_acc: 0.6908
Epoch 10/50
 - 70s - loss: 0.5912 - acc: 0.7931 - val_loss: 1.2336 - val_acc: 0.6482
Epoch 11/50
 - 70s - loss: 0.5495 - acc: 0.8073 - val_loss: 1.5170 - val_acc: 0.5622
Epoch 12/50
 - 70s - loss: 0.5079 - acc: 0.8227 - val_loss: 0.6742 - val_acc: 0.7710
Epoch 13/50
 - 70s - loss: 0.4711 - acc: 0.8344 - val_loss: 1.0713 - val_acc: 0.6912
Epoch 14/50
 - 70s - loss: 0.4340 - acc: 0.8482 - val_loss: 1.0542 - val_acc: 0.7102
Epoch 15/50
 - 70s - loss: 0.4070 - acc: 0.8586 - val_loss: 0.6531 - val_acc: 0.7882
Epoch 16/50
 - 70s - loss: 0.3801 - acc: 0.8669 - val_loss: 0.7751 - val_acc: 0.7544
Epoch 17/50
 - 70s - loss: 0.3505 - acc: 0.8782 - val_loss: 0.7836 - val_acc: 0.7540
Epoch 18/50
 - 70s - loss: 0.3229 - acc: 0.8879 - val_loss: 1.3389 - val_acc: 0.6630
Epoch 19/50
 - 70s - loss: 0.3005 - acc: 0.8959 - val_loss: 0.8804 - val_acc: 0.7520
Epoch 20/50
 - 70s - loss: 0.2762 - acc: 0.9047 - val_loss: 0.6886 - val_acc: 0.7886
Epoch 21/50
 - 70s - loss: 0.2568 - acc: 0.9123 - val_loss: 0.8559 - val_acc: 0.7510
Epoch 22/50
 - 70s - loss: 0.2357 - acc: 0.9191 - val_loss: 0.7257 - val_acc: 0.7910
Epoch 23/50
 - 70s - loss: 0.2154 - acc: 0.9252 - val_loss: 1.0626 - val_acc: 0.7314
Epoch 24/50
 - 70s - loss: 0.2012 - acc: 0.9301 - val_loss: 0.8184 - val_acc: 0.7842
Epoch 25/50
 - 70s - loss: 0.1813 - acc: 0.9368 - val_loss: 0.8605 - val_acc: 0.7712
Epoch 26/50
 - 70s - loss: 0.1660 - acc: 0.9434 - val_loss: 0.7771 - val_acc: 0.7802
Epoch 27/50
 - 70s - loss: 0.1517 - acc: 0.9481 - val_loss: 0.7128 - val_acc: 0.8090
Epoch 28/50
 - 70s - loss: 0.1370 - acc: 0.9545 - val_loss: 0.7039 - val_acc: 0.8082
Epoch 29/50
 - 70s - loss: 0.1240 - acc: 0.9593 - val_loss: 0.8285 - val_acc: 0.7944
Epoch 30/50
 - 70s - loss: 0.1143 - acc: 0.9619 - val_loss: 0.7014 - val_acc: 0.8148
Epoch 31/50
 - 70s - loss: 0.1084 - acc: 0.9644 - val_loss: 0.7889 - val_acc: 0.8028
Epoch 32/50
 - 70s - loss: 0.0943 - acc: 0.9689 - val_loss: 0.8615 - val_acc: 0.7860
Epoch 33/50
 - 70s - loss: 0.0859 - acc: 0.9720 - val_loss: 0.8321 - val_acc: 0.8038
Epoch 34/50
 - 70s - loss: 0.0774 - acc: 0.9754 - val_loss: 0.8828 - val_acc: 0.7910
Epoch 35/50
 - 70s - loss: 0.0748 - acc: 0.9754 - val_loss: 1.3027 - val_acc: 0.7474
Epoch 36/50
 - 70s - loss: 0.0674 - acc: 0.9803 - val_loss: 0.7603 - val_acc: 0.8212
Epoch 37/50
 - 70s - loss: 0.0613 - acc: 0.9809 - val_loss: 0.8013 - val_acc: 0.8092
Epoch 38/50
 - 70s - loss: 0.0558 - acc: 0.9829 - val_loss: 0.8317 - val_acc: 0.8096
Epoch 39/50
 - 70s - loss: 0.0538 - acc: 0.9833 - val_loss: 0.7182 - val_acc: 0.8270
Epoch 40/50
 - 70s - loss: 0.0511 - acc: 0.9848 - val_loss: 0.7937 - val_acc: 0.8190
Epoch 41/50
 - 70s - loss: 0.0468 - acc: 0.9861 - val_loss: 0.7225 - val_acc: 0.8298
Epoch 42/50
 - 70s - loss: 0.0423 - acc: 0.9878 - val_loss: 0.7175 - val_acc: 0.8396
Epoch 43/50
 - 70s - loss: 0.0403 - acc: 0.9877 - val_loss: 0.7226 - val_acc: 0.8358
Epoch 44/50
 - 70s - loss: 0.0386 - acc: 0.9885 - val_loss: 0.9894 - val_acc: 0.7938
Epoch 45/50
 - 70s - loss: 0.0347 - acc: 0.9904 - val_loss: 0.8615 - val_acc: 0.8174
Epoch 46/50
 - 70s - loss: 0.0342 - acc: 0.9903 - val_loss: 0.9995 - val_acc: 0.8026
Epoch 47/50
 - 70s - loss: 0.0324 - acc: 0.9914 - val_loss: 0.7506 - val_acc: 0.8350
Epoch 48/50
 - 70s - loss: 0.0289 - acc: 0.9918 - val_loss: 0.6600 - val_acc: 0.8468
Epoch 49/50
 - 70s - loss: 0.0279 - acc: 0.9924 - val_loss: 0.7129 - val_acc: 0.8412
Epoch 50/50
 - 70s - loss: 0.0283 - acc: 0.9923 - val_loss: 0.8061 - val_acc: 0.8350
3503.600162267685
--------
{'val_loss': [2.558652638244629, 1.7456994918823243, 1.7995555240631103, 1.3247181003570556, 1.4275736907958985, 1.331254116821289, 1.0023922203063964, 1.629467155456543, 0.9009123762130737, 1.2336392093658448, 1.5169987522125243, 0.6742287754058838, 1.0712514991760254, 1.0542121910095215, 0.6531419422149658, 0.7750947956085205, 0.7835603477478027, 1.338867378616333, 0.8803621012687683, 0.6885926271438598, 0.8559214302062988, 0.7257213088989258, 1.062604084777832, 0.8184121925354004, 0.8605383029937744, 0.777122741317749, 0.712815145111084, 0.7038667753219604, 0.8284788177490234, 0.7013758665084839, 0.7889252349853516, 0.8615267188072204, 0.8320552318572998, 0.8828387227058411, 1.3026880508422851, 0.760301827430725, 0.8012823589324951, 0.8316791967391968, 0.7181613216400147, 0.7936855554580688, 0.7225241733551026, 0.7175210689544678, 0.7225529178619384, 0.9894301582336426, 0.861504948425293, 0.9994936043739319, 0.750576329421997, 0.6599950286865235, 0.7128704484939575, 0.8061190265655518], 'val_acc': [0.2312, 0.4244, 0.439, 0.5518, 0.5342, 0.5762, 0.6578, 0.5322, 0.6908, 0.6482, 0.5622, 0.771, 0.6912, 0.7102, 0.7882, 0.7544, 0.754, 0.663, 0.752, 0.7886, 0.751, 0.791, 0.7314, 0.7842, 0.7712, 0.7802, 0.809, 0.8082, 0.7944, 0.8148, 0.8028, 0.786, 0.8038, 0.791, 0.7474, 0.8212, 0.8092, 0.8096, 0.827, 0.819, 0.8298, 0.8396, 0.8358, 0.7938, 0.8174, 0.8026, 0.835, 0.8468, 0.8412, 0.835], 'loss': [3.099778136846754, 1.5116103330400255, 1.2677470424228245, 1.0957272822274102, 0.9509738857269288, 0.8440426341586643, 0.7632938213348389, 0.7000592374271817, 0.6425954357994927, 0.5911955484284295, 0.5495086661656697, 0.5078580140219794, 0.4710878545602163, 0.43403091312514414, 0.4069935843096839, 0.3800600834634569, 0.3505055212656657, 0.32291148721377055, 0.3005176714791192, 0.2762131490919325, 0.25682904339896306, 0.23566532501644558, 0.21537331041495006, 0.20124826827843983, 0.18126777923372056, 0.16595055683718787, 0.15168978386720022, 0.13701847321457333, 0.12398238311078813, 0.11425121511353387, 0.10835804234610663, 0.09431967758205202, 0.08590693779852655, 0.07738513450092739, 0.07481528642045127, 0.06735275473859575, 0.06132994923988978, 0.05578459719551934, 0.05378999208344354, 0.05105502482785119, 0.04675312532848782, 0.04225761321915521, 0.04032833921379513, 0.03864178316328261, 0.034679953174127476, 0.03415492655701107, 0.03244567034145196, 0.02894122687809997, 0.02794799138108889, 0.02826547985871633], 'acc': [0.3189555555343628, 0.4812888888888889, 0.562044444433848, 0.6207333333439297, 0.6664444444762336, 0.7043777777777778, 0.7291333333545261, 0.7574666666878594, 0.7743555555449592, 0.7931333332909478, 0.8073111111217075, 0.8226666666666667, 0.8343777777777778, 0.8481777777459887, 0.8586000000317892, 0.8668888888570997, 0.8781777777883741, 0.8879333333227369, 0.8958888888888888, 0.9047111111323038, 0.9122666666984558, 0.9191111110687256, 0.9251777778095669, 0.9301333332909478, 0.9367777778201632, 0.9433777778201633, 0.9480666666348775, 0.9545333333121405, 0.9592666666242812, 0.9619333333121406, 0.9644444444020589, 0.9688888888782925, 0.9719777777777778, 0.9754222222010295, 0.9753555555343628, 0.9802666666348775, 0.9809111110687256, 0.9828666666878594, 0.9832666666560703, 0.9847777777671815, 0.9861333333121406, 0.9877999999682109, 0.9877333333227369, 0.9885333333121405, 0.9903555555555555, 0.9902666666454739, 0.9914444444444445, 0.9918, 0.9924, 0.992333333322737]}
===Final Test Score===
Test loss: 0.8368248397469521
Test accuracy: 0.8227
