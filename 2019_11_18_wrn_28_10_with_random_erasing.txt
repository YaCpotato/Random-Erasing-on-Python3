[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 179579688907939546
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 832755217895677426
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:1"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 12408372605898840570
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:2"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 4744740607208538117
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:3"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 3199569935214532622
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 4117027257258518673
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 12229847451496767664
physical_device_desc: "device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3d:00.0, compute capability: 7.0"
, name: "/device:GPU:1"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 8443458039716237528
physical_device_desc: "device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3e:00.0, compute capability: 7.0"
, name: "/device:GPU:2"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 7856043329592020002
physical_device_desc: "device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b1:00.0, compute capability: 7.0"
, name: "/device:GPU:3"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 18412522969052174898
physical_device_desc: "device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b2:00.0, compute capability: 7.0"
]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 160)  23200       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 160)  0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 160)  230560      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 160)  2720        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 160)  230560      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 32, 32, 160)  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 160)  230560      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 160)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 160)  230560      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 32, 32, 160)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 160)  230560      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 160)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 160)  230560      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 32, 32, 160)  0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 160)  230560      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 160)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  461120      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 16, 16, 320)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 320)  921920      dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 320)  51520       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 320)  921920      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 16, 16, 320)  0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 320)  921920      dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 320)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 320)  921920      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 16, 320)  0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 320)  921920      dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 320)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 320)  921920      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 16, 16, 320)  0           activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 320)  921920      dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 320)  1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 320)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 320)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 320)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 640)    1843840     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 8, 8, 640)    0           activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 640)    205440      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 640)    3687040     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 8, 8, 640)    0           activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 640)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 640)    3687040     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 8, 8, 640)    0           activation_22[0][0]              
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_11[0][0]                 
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 640)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 640)    3687040     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 8, 8, 640)    0           activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 640)    2560        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 640)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 640)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 640)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           6410        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,507,242
Trainable params: 36,489,290
Non-trainable params: 17,952
__________________________________________________________________________________________________
Train on 45000 samples, validate on 5000 samples
Epoch 1/50
 - 78s - loss: 14.4236 - acc: 0.1007 - val_loss: 14.5297 - val_acc: 0.0976
Epoch 2/50
 - 70s - loss: 14.5020 - acc: 0.1003 - val_loss: 14.5295 - val_acc: 0.0976
Epoch 3/50
 - 70s - loss: 14.5020 - acc: 0.1003 - val_loss: 14.5296 - val_acc: 0.0976
Epoch 4/50
 - 70s - loss: 14.5020 - acc: 0.1003 - val_loss: 14.5295 - val_acc: 0.0976
Epoch 5/50
 - 70s - loss: 8.9038 - acc: 0.1875 - val_loss: 2.9081 - val_acc: 0.1604
Epoch 6/50
 - 70s - loss: 1.8041 - acc: 0.3991 - val_loss: 2.5072 - val_acc: 0.2710
Epoch 7/50
 - 70s - loss: 1.4899 - acc: 0.4913 - val_loss: 2.0047 - val_acc: 0.3944
Epoch 8/50
 - 70s - loss: 1.3264 - acc: 0.5462 - val_loss: 1.6423 - val_acc: 0.4864
Epoch 9/50
 - 70s - loss: 1.1659 - acc: 0.5903 - val_loss: 1.5324 - val_acc: 0.5136
Epoch 10/50
 - 70s - loss: 1.0349 - acc: 0.6331 - val_loss: 1.5159 - val_acc: 0.5154
Epoch 11/50
 - 70s - loss: 0.9398 - acc: 0.6656 - val_loss: 1.1328 - val_acc: 0.6116
Epoch 12/50
 - 70s - loss: 0.8711 - acc: 0.6919 - val_loss: 1.0834 - val_acc: 0.6444
Epoch 13/50
 - 70s - loss: 0.8123 - acc: 0.7123 - val_loss: 1.0650 - val_acc: 0.6352
Epoch 14/50
 - 70s - loss: 0.7587 - acc: 0.7341 - val_loss: 1.5241 - val_acc: 0.5890
Epoch 15/50
 - 70s - loss: 0.7092 - acc: 0.7494 - val_loss: 1.0741 - val_acc: 0.6538
Epoch 16/50
 - 70s - loss: 0.6683 - acc: 0.7639 - val_loss: 0.9194 - val_acc: 0.6880
Epoch 17/50
 - 70s - loss: 0.6287 - acc: 0.7786 - val_loss: 0.8727 - val_acc: 0.7056
Epoch 18/50
 - 70s - loss: 0.5958 - acc: 0.7907 - val_loss: 0.8845 - val_acc: 0.7120
Epoch 19/50
 - 70s - loss: 0.5570 - acc: 0.8041 - val_loss: 1.2327 - val_acc: 0.6238
Epoch 20/50
 - 70s - loss: 0.5260 - acc: 0.8154 - val_loss: 0.8782 - val_acc: 0.7132
Epoch 21/50
 - 70s - loss: 0.4978 - acc: 0.8258 - val_loss: 1.1578 - val_acc: 0.6674
Epoch 22/50
 - 70s - loss: 0.4662 - acc: 0.8359 - val_loss: 1.4447 - val_acc: 0.6186
Epoch 23/50
 - 70s - loss: 0.4418 - acc: 0.8443 - val_loss: 1.1767 - val_acc: 0.6528
Epoch 24/50
 - 70s - loss: 0.4140 - acc: 0.8544 - val_loss: 0.8239 - val_acc: 0.7354
Epoch 25/50
 - 70s - loss: 0.3871 - acc: 0.8646 - val_loss: 0.8148 - val_acc: 0.7472
Epoch 26/50
 - 70s - loss: 0.3646 - acc: 0.8724 - val_loss: 0.8994 - val_acc: 0.7238
Epoch 27/50
 - 70s - loss: 0.3425 - acc: 0.8797 - val_loss: 1.3624 - val_acc: 0.6432
Epoch 28/50
 - 70s - loss: 0.3195 - acc: 0.8894 - val_loss: 0.8864 - val_acc: 0.7518
Epoch 29/50
 - 70s - loss: 0.2926 - acc: 0.8992 - val_loss: 0.9104 - val_acc: 0.7514
Epoch 30/50
 - 70s - loss: 0.2749 - acc: 0.9062 - val_loss: 0.9934 - val_acc: 0.7246
Epoch 31/50
 - 70s - loss: 0.2532 - acc: 0.9136 - val_loss: 0.9603 - val_acc: 0.7366
Epoch 32/50
 - 70s - loss: 0.2382 - acc: 0.9179 - val_loss: 1.4799 - val_acc: 0.6244
Epoch 33/50
 - 70s - loss: 0.2209 - acc: 0.9248 - val_loss: 1.2112 - val_acc: 0.7276
Epoch 34/50
 - 70s - loss: 0.2068 - acc: 0.9286 - val_loss: 0.9248 - val_acc: 0.7498
Epoch 35/50
 - 70s - loss: 0.1881 - acc: 0.9350 - val_loss: 0.8696 - val_acc: 0.7604
Epoch 36/50
 - 70s - loss: 0.1692 - acc: 0.9437 - val_loss: 1.3140 - val_acc: 0.6942
Epoch 37/50
 - 70s - loss: 0.1596 - acc: 0.9450 - val_loss: 0.9797 - val_acc: 0.7590
Epoch 38/50
 - 70s - loss: 0.1453 - acc: 0.9505 - val_loss: 1.3076 - val_acc: 0.6928
Epoch 39/50
 - 70s - loss: 0.1390 - acc: 0.9527 - val_loss: 0.8362 - val_acc: 0.7854
Epoch 40/50
 - 70s - loss: 0.1262 - acc: 0.9576 - val_loss: 0.9302 - val_acc: 0.7666
Epoch 41/50
 - 70s - loss: 0.1170 - acc: 0.9618 - val_loss: 1.1866 - val_acc: 0.7400
Epoch 42/50
 - 70s - loss: 0.1089 - acc: 0.9630 - val_loss: 1.4004 - val_acc: 0.7040
Epoch 43/50
 - 70s - loss: 0.1019 - acc: 0.9670 - val_loss: 1.1837 - val_acc: 0.7290
Epoch 44/50
 - 70s - loss: 0.0905 - acc: 0.9705 - val_loss: 0.9729 - val_acc: 0.7824
Epoch 45/50
 - 70s - loss: 0.0823 - acc: 0.9733 - val_loss: 0.9015 - val_acc: 0.7996
Epoch 46/50
 - 70s - loss: 0.0812 - acc: 0.9733 - val_loss: 1.0059 - val_acc: 0.7782
Epoch 47/50
 - 70s - loss: 0.0744 - acc: 0.9766 - val_loss: 0.9977 - val_acc: 0.7768
Epoch 48/50
 - 70s - loss: 0.0702 - acc: 0.9778 - val_loss: 0.9176 - val_acc: 0.7912
Epoch 49/50
 - 70s - loss: 0.0656 - acc: 0.9802 - val_loss: 0.8617 - val_acc: 0.7998
Epoch 50/50
 - 70s - loss: 0.0625 - acc: 0.9800 - val_loss: 0.8780 - val_acc: 0.7988
3504.705357313156
--------
{'val_loss': [14.529661430358887, 14.529544999694824, 14.529563383483886, 14.529541801452636, 2.9080822467803955, 2.507238732910156, 2.004665493774414, 1.6422565872192383, 1.5323776611328126, 1.5158759447097778, 1.1327960718154908, 1.0834001274108886, 1.064973250579834, 1.5240811223983766, 1.0741413074493409, 0.9193752685546875, 0.8727334440231324, 0.8845201357841491, 1.2327373733520508, 0.8781774053573609, 1.1578183307647705, 1.4447141870498657, 1.1766842397689818, 0.8239054437637329, 0.8147582405090332, 0.8994231563568115, 1.3623845623016357, 0.8864453607559204, 0.9104166355133056, 0.9934340209960938, 0.9602943672180175, 1.4798819850921632, 1.211226355457306, 0.9247998910903931, 0.8695623546600342, 1.3140143516540528, 0.9796565498352051, 1.3076152610778808, 0.8362130708694459, 0.9301918441772461, 1.1865727989196777, 1.400397785949707, 1.1837134838104248, 0.9728965972900391, 0.9014870857238769, 1.005875193786621, 0.9977083045959473, 0.9175953514099121, 0.8616854640960694, 0.8780053190231323], 'val_acc': [0.0976, 0.0976, 0.0976, 0.0976, 0.1604, 0.271, 0.3944, 0.4864, 0.5136, 0.5154, 0.6116, 0.6444, 0.6352, 0.589, 0.6538, 0.688, 0.7056, 0.712, 0.6238, 0.7132, 0.6674, 0.6186, 0.6528, 0.7354, 0.7472, 0.7238, 0.6432, 0.7518, 0.7514, 0.7246, 0.7366, 0.6244, 0.7276, 0.7498, 0.7604, 0.6942, 0.759, 0.6928, 0.7854, 0.7666, 0.74, 0.704, 0.729, 0.7824, 0.7996, 0.7782, 0.7768, 0.7912, 0.7998, 0.7988], 'loss': [14.423592860921223, 14.501987552218967, 14.501987543741862, 14.501987566630046, 8.903777365705702, 1.804090303209093, 1.4899017249213324, 1.3263730029847887, 1.1659329959869384, 1.0349074121687147, 0.9397644504335192, 0.8711053740819296, 0.8123266349368625, 0.7587364699893527, 0.709214704937405, 0.6682944352467854, 0.6287207377751668, 0.5957709122021994, 0.5569796934657627, 0.5259910237206353, 0.4977503388828701, 0.4662193532837762, 0.44179670181274416, 0.4139605738215976, 0.38706641454696655, 0.36460957125027976, 0.34253109087414213, 0.3195139334466722, 0.29256351484192744, 0.2749410823610094, 0.2531809374173482, 0.23824479287995232, 0.22090629091792635, 0.20681088005171883, 0.18813919659720527, 0.16918067106670803, 0.15963685421148935, 0.14530793341530693, 0.1390221424155765, 0.12617560799916586, 0.11704508896403842, 0.10886099387672213, 0.1018656181494395, 0.09046835709147984, 0.08229193189938863, 0.08116654720107715, 0.07442585873670048, 0.07024349206487338, 0.06560517824027273, 0.06251172417799632], 'acc': [0.10068888889418708, 0.10026666666931576, 0.10026666666666667, 0.10026666666666667, 0.18748888889948526, 0.3991333333545261, 0.49133333333333334, 0.5461777777883742, 0.590333333322737, 0.6331333333651225, 0.6655777777459886, 0.6919111111323039, 0.7122888889100817, 0.7341333333333333, 0.7493555555979411, 0.7638888889206781, 0.7785555555449591, 0.7906888889100816, 0.8041111111217075, 0.8154444444232517, 0.8257777777883741, 0.8358888889312744, 0.8442666666984558, 0.85435555551317, 0.8646222221798368, 0.87244444448683, 0.8796666667090522, 0.8893777777989705, 0.8992444444868299, 0.9062444444338481, 0.9135999999576144, 0.9179111111323038, 0.9247777777459887, 0.9285555555343628, 0.93495555551317, 0.943688888920678, 0.9449555555237664, 0.9505111111005148, 0.9527111110793219, 0.9575777777353922, 0.961777777756585, 0.9630222222010295, 0.9670444444232517, 0.970533333322737, 0.9733333333121406, 0.9733333333333334, 0.9766444444444444, 0.9777555555555556, 0.9802222222116258, 0.9799999999576144]}
===Final Test Score===
Test loss: 0.8152889654517174
Test accuracy: 0.8172
