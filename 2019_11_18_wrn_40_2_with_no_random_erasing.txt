[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 5514679017064153274
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 10181288008462912434
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:1"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 16005890173284719450
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:2"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 12916796960800365316
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:3"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 6685528763844788012
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 16951549000988777517
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 14125224746683196037
physical_device_desc: "device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3d:00.0, compute capability: 7.0"
, name: "/device:GPU:1"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 13925412860110374845
physical_device_desc: "device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3e:00.0, compute capability: 7.0"
, name: "/device:GPU:2"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 5803543065251395869
physical_device_desc: "device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b1:00.0, compute capability: 7.0"
, name: "/device:GPU:3"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 4965201677344606392
physical_device_desc: "device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b2:00.0, compute capability: 7.0"
]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 32)   4640        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 32)   0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 32)   9248        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 32)   544         activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 32)   0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 32)   9248        add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 32, 32, 32)   0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 32)   9248        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 32)   0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 32)   9248        add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 32)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 32, 32, 32)   0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 32)   9248        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 32)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 32)   0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 32)   9248        add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 32, 32, 32)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 32)   9248        dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 32)   128         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 32)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 32)   0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 32)   9248        add_4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 32)   128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 32, 32, 32)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 32)   9248        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 32)   0           add_4[0][0]                      
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 32, 32, 32)   9248        add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 32)   128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 32, 32, 32)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 32)   9248        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 32)   128         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 32)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 32)   0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 16, 64)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 64)   36928       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 64)   2112        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 64)   0           conv2d_15[0][0]                  
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 64)   36928       add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 16, 16, 64)   0           activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 64)   36928       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 64)   0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 16, 16, 64)   36928       add_8[0][0]                      
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 16, 16, 64)   0           activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 16, 16, 64)   36928       dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 64)   0           add_8[0][0]                      
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 16, 16, 64)   36928       add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_22[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 16, 16, 64)   0           activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 16, 16, 64)   36928       dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 64)   0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 16, 16, 64)   36928       add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 64)   256         conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 16, 16, 64)   0           activation_22[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 16, 16, 64)   36928       dropout_11[0][0]                 
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 64)   0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 16, 64)   36928       add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 16, 16, 64)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 16, 16, 64)   0           activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 16, 16, 64)   36928       dropout_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 64)   256         conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 64)   0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 8, 8, 128)    0           activation_26[0][0]              
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 8, 8, 128)    147584      dropout_13[0][0]                 
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 128)    8320        max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 8, 8, 128)    0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 128)    0           conv2d_28[0][0]                  
                                                                 activation_27[0][0]              
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 8, 8, 128)    147584      add_13[0][0]                     
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 128)    512         conv2d_31[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 8, 8, 128)    0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 8, 8, 128)    0           activation_28[0][0]              
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 8, 8, 128)    147584      dropout_14[0][0]                 
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 128)    512         conv2d_32[0][0]                  
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 8, 8, 128)    0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 128)    0           add_13[0][0]                     
                                                                 activation_29[0][0]              
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 8, 8, 128)    147584      add_14[0][0]                     
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 128)    512         conv2d_33[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 8, 8, 128)    0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 8, 8, 128)    0           activation_30[0][0]              
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 8, 8, 128)    147584      dropout_15[0][0]                 
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 128)    512         conv2d_34[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 8, 8, 128)    0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 128)    0           add_14[0][0]                     
                                                                 activation_31[0][0]              
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 8, 8, 128)    147584      add_15[0][0]                     
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 8, 8, 128)    512         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 8, 8, 128)    0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 8, 8, 128)    0           activation_32[0][0]              
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 8, 8, 128)    147584      dropout_16[0][0]                 
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 8, 8, 128)    512         conv2d_36[0][0]                  
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 8, 8, 128)    0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
add_16 (Add)                    (None, 8, 8, 128)    0           add_15[0][0]                     
                                                                 activation_33[0][0]              
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 8, 8, 128)    147584      add_16[0][0]                     
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 8, 8, 128)    512         conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 8, 8, 128)    0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 8, 8, 128)    0           activation_34[0][0]              
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 8, 8, 128)    147584      dropout_17[0][0]                 
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 8, 8, 128)    512         conv2d_38[0][0]                  
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 8, 8, 128)    0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
add_17 (Add)                    (None, 8, 8, 128)    0           add_16[0][0]                     
                                                                 activation_35[0][0]              
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 8, 8, 128)    147584      add_17[0][0]                     
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 8, 8, 128)    512         conv2d_39[0][0]                  
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 8, 8, 128)    0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 8, 8, 128)    0           activation_36[0][0]              
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 8, 8, 128)    147584      dropout_18[0][0]                 
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 8, 8, 128)    512         conv2d_40[0][0]                  
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 8, 8, 128)    0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
add_18 (Add)                    (None, 8, 8, 128)    0           add_17[0][0]                     
                                                                 activation_37[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 128)          0           add_18[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           1290        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 2,251,882
Trainable params: 2,246,474
Non-trainable params: 5,408
__________________________________________________________________________________________________
Train on 45000 samples, validate on 5000 samples
Epoch 1/50
 - 25s - loss: 2.1379 - acc: 0.3240 - val_loss: 1.9699 - val_acc: 0.3502
Epoch 2/50
 - 17s - loss: 1.4829 - acc: 0.4656 - val_loss: 1.6338 - val_acc: 0.4368
Epoch 3/50
 - 17s - loss: 1.3009 - acc: 0.5319 - val_loss: 1.6132 - val_acc: 0.4430
Epoch 4/50
 - 17s - loss: 1.1898 - acc: 0.5739 - val_loss: 1.8075 - val_acc: 0.4318
Epoch 5/50
 - 17s - loss: 1.1005 - acc: 0.6066 - val_loss: 1.2241 - val_acc: 0.5824
Epoch 6/50
 - 17s - loss: 1.0250 - acc: 0.6326 - val_loss: 1.6650 - val_acc: 0.4778
Epoch 7/50
 - 17s - loss: 0.9715 - acc: 0.6526 - val_loss: 1.5103 - val_acc: 0.5080
Epoch 8/50
 - 17s - loss: 0.9167 - acc: 0.6737 - val_loss: 1.1602 - val_acc: 0.5952
Epoch 9/50
 - 17s - loss: 0.8830 - acc: 0.6850 - val_loss: 0.9819 - val_acc: 0.6570
Epoch 10/50
 - 17s - loss: 0.8448 - acc: 0.6985 - val_loss: 0.9404 - val_acc: 0.6750
Epoch 11/50
 - 17s - loss: 0.8131 - acc: 0.7115 - val_loss: 0.9129 - val_acc: 0.6808
Epoch 12/50
 - 17s - loss: 0.7838 - acc: 0.7247 - val_loss: 1.1600 - val_acc: 0.6058
Epoch 13/50
 - 17s - loss: 0.7594 - acc: 0.7298 - val_loss: 1.7284 - val_acc: 0.4988
Epoch 14/50
 - 17s - loss: 0.7349 - acc: 0.7402 - val_loss: 1.0629 - val_acc: 0.6502
Epoch 15/50
 - 17s - loss: 0.7124 - acc: 0.7485 - val_loss: 0.8613 - val_acc: 0.7048
Epoch 16/50
 - 17s - loss: 0.6902 - acc: 0.7576 - val_loss: 0.9497 - val_acc: 0.6760
Epoch 17/50
 - 17s - loss: 0.6716 - acc: 0.7624 - val_loss: 0.9227 - val_acc: 0.6862
Epoch 18/50
 - 17s - loss: 0.6541 - acc: 0.7685 - val_loss: 0.7754 - val_acc: 0.7354
Epoch 19/50
 - 17s - loss: 0.6318 - acc: 0.7770 - val_loss: 0.7673 - val_acc: 0.7368
Epoch 20/50
 - 17s - loss: 0.6172 - acc: 0.7839 - val_loss: 0.8920 - val_acc: 0.7136
Epoch 21/50
 - 17s - loss: 0.6024 - acc: 0.7861 - val_loss: 0.8436 - val_acc: 0.7124
Epoch 22/50
 - 17s - loss: 0.5840 - acc: 0.7943 - val_loss: 0.9173 - val_acc: 0.7006
Epoch 23/50
 - 17s - loss: 0.5689 - acc: 0.7992 - val_loss: 0.7594 - val_acc: 0.7364
Epoch 24/50
 - 17s - loss: 0.5555 - acc: 0.8054 - val_loss: 0.8845 - val_acc: 0.7104
Epoch 25/50
 - 17s - loss: 0.5435 - acc: 0.8087 - val_loss: 0.7105 - val_acc: 0.7538
Epoch 26/50
 - 17s - loss: 0.5334 - acc: 0.8128 - val_loss: 0.7112 - val_acc: 0.7606
Epoch 27/50
 - 17s - loss: 0.5169 - acc: 0.8187 - val_loss: 0.6732 - val_acc: 0.7718
Epoch 28/50
 - 17s - loss: 0.5105 - acc: 0.8193 - val_loss: 0.7708 - val_acc: 0.7384
Epoch 29/50
 - 17s - loss: 0.4989 - acc: 0.8221 - val_loss: 0.7940 - val_acc: 0.7372
Epoch 30/50
 - 17s - loss: 0.4876 - acc: 0.8284 - val_loss: 0.7398 - val_acc: 0.7602
Epoch 31/50
 - 17s - loss: 0.4742 - acc: 0.8335 - val_loss: 0.6986 - val_acc: 0.7702
Epoch 32/50
 - 17s - loss: 0.4640 - acc: 0.8380 - val_loss: 0.6191 - val_acc: 0.7944
Epoch 33/50
 - 17s - loss: 0.4538 - acc: 0.8410 - val_loss: 0.7031 - val_acc: 0.7660
Epoch 34/50
 - 17s - loss: 0.4498 - acc: 0.8423 - val_loss: 0.6543 - val_acc: 0.7824
Epoch 35/50
 - 17s - loss: 0.4356 - acc: 0.8468 - val_loss: 0.6264 - val_acc: 0.7940
Epoch 36/50
 - 17s - loss: 0.4291 - acc: 0.8475 - val_loss: 0.6653 - val_acc: 0.7832
Epoch 37/50
 - 17s - loss: 0.4199 - acc: 0.8532 - val_loss: 0.6453 - val_acc: 0.7860
Epoch 38/50
 - 17s - loss: 0.4111 - acc: 0.8556 - val_loss: 0.6324 - val_acc: 0.7946
Epoch 39/50
 - 17s - loss: 0.4027 - acc: 0.8579 - val_loss: 0.6395 - val_acc: 0.7918
Epoch 40/50
 - 17s - loss: 0.3981 - acc: 0.8591 - val_loss: 0.7212 - val_acc: 0.7696
Epoch 41/50
 - 17s - loss: 0.3875 - acc: 0.8624 - val_loss: 0.6384 - val_acc: 0.7928
Epoch 42/50
 - 17s - loss: 0.3802 - acc: 0.8651 - val_loss: 0.6615 - val_acc: 0.7828
Epoch 43/50
 - 17s - loss: 0.3722 - acc: 0.8700 - val_loss: 0.6657 - val_acc: 0.7866
Epoch 44/50
 - 17s - loss: 0.3626 - acc: 0.8726 - val_loss: 0.7198 - val_acc: 0.7750
Epoch 45/50
 - 17s - loss: 0.3566 - acc: 0.8755 - val_loss: 0.7166 - val_acc: 0.7754
Epoch 46/50
 - 17s - loss: 0.3494 - acc: 0.8765 - val_loss: 0.6305 - val_acc: 0.7986
Epoch 47/50
 - 17s - loss: 0.3441 - acc: 0.8799 - val_loss: 1.0005 - val_acc: 0.7190
Epoch 48/50
 - 17s - loss: 0.3358 - acc: 0.8817 - val_loss: 0.7416 - val_acc: 0.7786
Epoch 49/50
 - 17s - loss: 0.3332 - acc: 0.8836 - val_loss: 0.7834 - val_acc: 0.7624
Epoch 50/50
 - 17s - loss: 0.3218 - acc: 0.8870 - val_loss: 0.7266 - val_acc: 0.7878
870.0656378269196
--------
{'val_loss': [1.969869875717163, 1.6338436233520508, 1.6132115676879883, 1.8074819938659668, 1.2241333087921142, 1.6649572116851807, 1.5102610542297363, 1.1602414150238036, 0.9819021808624268, 0.9403703525543213, 0.9128575439453125, 1.1600016494750978, 1.7283677154541015, 1.062864039993286, 0.861326179599762, 0.9497220859527588, 0.9227233581542968, 0.7753748735427857, 0.7673306235313415, 0.8919871702194214, 0.8436117105484009, 0.9172826362609863, 0.7593906194686889, 0.8845424362182617, 0.7105392523765564, 0.711235633468628, 0.6732478496551514, 0.7708261508941651, 0.7939924808502197, 0.73982604637146, 0.6986124147415161, 0.6190955678939819, 0.7031171842575074, 0.6543198696136474, 0.6263525866508484, 0.6652923166275024, 0.6453234844207764, 0.6323558955192566, 0.6394811103820801, 0.7212486408233643, 0.6384310545921326, 0.6614551650047302, 0.6656581218719483, 0.7197962413787842, 0.7166310958862304, 0.6305336168289185, 1.000479360961914, 0.7416388438224792, 0.7833510204315186, 0.7266176670074463], 'val_acc': [0.3502, 0.4368, 0.443, 0.4318, 0.5824, 0.4778, 0.508, 0.5952, 0.657, 0.675, 0.6808, 0.6058, 0.4988, 0.6502, 0.7048, 0.676, 0.6862, 0.7354, 0.7368, 0.7136, 0.7124, 0.7006, 0.7364, 0.7104, 0.7538, 0.7606, 0.7718, 0.7384, 0.7372, 0.7602, 0.7702, 0.7944, 0.766, 0.7824, 0.794, 0.7832, 0.786, 0.7946, 0.7918, 0.7696, 0.7928, 0.7828, 0.7866, 0.775, 0.7754, 0.7986, 0.719, 0.7786, 0.7624, 0.7878], 'loss': [2.1378725170347423, 1.4828892643610636, 1.3008613033718532, 1.1898478830125596, 1.100454948510064, 1.0250365416208902, 0.9714582675298055, 0.9167221563127306, 0.8830345524258084, 0.8447761083390978, 0.8131364128642612, 0.7837894762039185, 0.7594039340019226, 0.7348875736236572, 0.7123829018804763, 0.6901590941852993, 0.6716496360672845, 0.6541104729970296, 0.6318297752592299, 0.6172438052707249, 0.6023683184305827, 0.58400524831348, 0.5688710530810887, 0.5554789711846245, 0.5434859366840786, 0.533416588804457, 0.5168521418465508, 0.5105056415345933, 0.4988870741314358, 0.48760446592436896, 0.4741848455535041, 0.4640342049598694, 0.45379981347190007, 0.44984205016560025, 0.4355550953918033, 0.4290716061062283, 0.41986592218610974, 0.4111011877801683, 0.40274585077497693, 0.3980698194079929, 0.3875238298787011, 0.38020141853756373, 0.3721845337020026, 0.36256094575987924, 0.35661964394781326, 0.34937950864368017, 0.3441218580987718, 0.33581877791086834, 0.3332418152650197, 0.3218261765003204], 'acc': [0.32402222220102944, 0.46559999997880724, 0.5318666666454739, 0.5739333333333333, 0.6066, 0.6326222221904331, 0.652622222243415, 0.6737333333651224, 0.6849555555343628, 0.6985111111323039, 0.7114888888888888, 0.7246888888994852, 0.7297777777883742, 0.7402222222116258, 0.7485333333333334, 0.75764444448683, 0.7623555555873447, 0.7684888889312744, 0.777044444433848, 0.783933333322737, 0.7861111110899184, 0.7942888888676961, 0.7992000000105964, 0.8053777777459886, 0.8087333333757188, 0.812777777756585, 0.8187111110793219, 0.8193111110687256, 0.8220666666984559, 0.8283999999682109, 0.8334888889312744, 0.8379777777671814, 0.8409555555767483, 0.8422666667090521, 0.8467555555343628, 0.8475333333015442, 0.853155555566152, 0.8556000000211927, 0.8579111110793219, 0.8590666666772631, 0.8623555555555555, 0.8651333333651224, 0.870022222243415, 0.8725777777883742, 0.875466666677263, 0.876466666677263, 0.8798666666666667, 0.8817111110899184, 0.8836222221904331, 0.8869999999576145]}
===Final Test Score===
Test loss: 0.7213370332717896
Test accuracy: 0.7812
