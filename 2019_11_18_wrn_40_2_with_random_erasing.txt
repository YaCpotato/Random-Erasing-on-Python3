[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 18034935829095916146
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 8950818272702749270
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:1"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 16615932991652547295
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:2"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 15540126309734167452
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:3"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 3446014107610547915
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 1344870010485740552
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 11896258952854964909
physical_device_desc: "device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3d:00.0, compute capability: 7.0"
, name: "/device:GPU:1"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 5185050778023663456
physical_device_desc: "device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3e:00.0, compute capability: 7.0"
, name: "/device:GPU:2"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 14432668442619947794
physical_device_desc: "device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b1:00.0, compute capability: 7.0"
, name: "/device:GPU:3"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 9791410166457579499
physical_device_desc: "device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b2:00.0, compute capability: 7.0"
]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 32)   4640        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 32)   0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 32)   9248        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 32)   544         activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 32)   0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 32)   9248        add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 32, 32, 32)   0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 32)   9248        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 32)   0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 32)   9248        add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 32)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 32, 32, 32)   0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 32)   9248        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 32)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 32)   0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 32)   9248        add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 32, 32, 32)   0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 32)   9248        dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 32)   128         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 32)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 32)   0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 32)   9248        add_4[0][0]                      
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 32)   128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 32, 32, 32)   0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 32)   9248        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 32)   0           add_4[0][0]                      
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 32, 32, 32)   9248        add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 32)   128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 32, 32, 32)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 32)   9248        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 32)   128         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 32)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 32)   0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 16, 64)   0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 64)   36928       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 64)   2112        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 64)   0           conv2d_15[0][0]                  
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 64)   36928       add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 16, 16, 64)   0           activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 64)   36928       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 64)   0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 16, 16, 64)   36928       add_8[0][0]                      
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 16, 16, 64)   0           activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 16, 16, 64)   36928       dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 64)   0           add_8[0][0]                      
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 16, 16, 64)   36928       add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_22[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 16, 16, 64)   0           activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 16, 16, 64)   36928       dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 64)   0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 16, 16, 64)   36928       add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 64)   256         conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 16, 16, 64)   0           activation_22[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 16, 16, 64)   36928       dropout_11[0][0]                 
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 64)   0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 16, 64)   36928       add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 16, 16, 64)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 16, 16, 64)   0           activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 16, 16, 64)   36928       dropout_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 64)   256         conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 64)   0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 8, 8, 128)    0           activation_26[0][0]              
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 8, 8, 128)    147584      dropout_13[0][0]                 
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 128)    8320        max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 8, 8, 128)    0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 128)    0           conv2d_28[0][0]                  
                                                                 activation_27[0][0]              
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 8, 8, 128)    147584      add_13[0][0]                     
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 128)    512         conv2d_31[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 8, 8, 128)    0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 8, 8, 128)    0           activation_28[0][0]              
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 8, 8, 128)    147584      dropout_14[0][0]                 
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 128)    512         conv2d_32[0][0]                  
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 8, 8, 128)    0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 128)    0           add_13[0][0]                     
                                                                 activation_29[0][0]              
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 8, 8, 128)    147584      add_14[0][0]                     
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 128)    512         conv2d_33[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 8, 8, 128)    0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 8, 8, 128)    0           activation_30[0][0]              
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 8, 8, 128)    147584      dropout_15[0][0]                 
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 128)    512         conv2d_34[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 8, 8, 128)    0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 128)    0           add_14[0][0]                     
                                                                 activation_31[0][0]              
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 8, 8, 128)    147584      add_15[0][0]                     
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 8, 8, 128)    512         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 8, 8, 128)    0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 8, 8, 128)    0           activation_32[0][0]              
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 8, 8, 128)    147584      dropout_16[0][0]                 
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 8, 8, 128)    512         conv2d_36[0][0]                  
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 8, 8, 128)    0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
add_16 (Add)                    (None, 8, 8, 128)    0           add_15[0][0]                     
                                                                 activation_33[0][0]              
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 8, 8, 128)    147584      add_16[0][0]                     
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 8, 8, 128)    512         conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 8, 8, 128)    0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 8, 8, 128)    0           activation_34[0][0]              
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 8, 8, 128)    147584      dropout_17[0][0]                 
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 8, 8, 128)    512         conv2d_38[0][0]                  
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 8, 8, 128)    0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
add_17 (Add)                    (None, 8, 8, 128)    0           add_16[0][0]                     
                                                                 activation_35[0][0]              
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 8, 8, 128)    147584      add_17[0][0]                     
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 8, 8, 128)    512         conv2d_39[0][0]                  
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 8, 8, 128)    0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 8, 8, 128)    0           activation_36[0][0]              
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 8, 8, 128)    147584      dropout_18[0][0]                 
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 8, 8, 128)    512         conv2d_40[0][0]                  
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 8, 8, 128)    0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
add_18 (Add)                    (None, 8, 8, 128)    0           add_17[0][0]                     
                                                                 activation_37[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 128)          0           add_18[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           1290        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 2,251,882
Trainable params: 2,246,474
Non-trainable params: 5,408
__________________________________________________________________________________________________
Train on 45000 samples, validate on 5000 samples
Epoch 1/50
 - 26s - loss: 2.2266 - acc: 0.3131 - val_loss: 1.8861 - val_acc: 0.3136
Epoch 2/50
 - 17s - loss: 1.5399 - acc: 0.4349 - val_loss: 2.0259 - val_acc: 0.3188
Epoch 3/50
 - 17s - loss: 1.4069 - acc: 0.4880 - val_loss: 2.3032 - val_acc: 0.2848
Epoch 4/50
 - 17s - loss: 1.3196 - acc: 0.5229 - val_loss: 2.3937 - val_acc: 0.3192
Epoch 5/50
 - 17s - loss: 1.2488 - acc: 0.5493 - val_loss: 1.6139 - val_acc: 0.4562
Epoch 6/50
 - 17s - loss: 1.1908 - acc: 0.5714 - val_loss: 1.8559 - val_acc: 0.4318
Epoch 7/50
 - 17s - loss: 1.1388 - acc: 0.5923 - val_loss: 1.3326 - val_acc: 0.5300
Epoch 8/50
 - 17s - loss: 1.0904 - acc: 0.6097 - val_loss: 1.3744 - val_acc: 0.5216
Epoch 9/50
 - 17s - loss: 1.0533 - acc: 0.6231 - val_loss: 1.3952 - val_acc: 0.5208
Epoch 10/50
 - 17s - loss: 1.0173 - acc: 0.6366 - val_loss: 1.1834 - val_acc: 0.5848
Epoch 11/50
 - 17s - loss: 0.9880 - acc: 0.6444 - val_loss: 1.4884 - val_acc: 0.5078
Epoch 12/50
 - 17s - loss: 0.9507 - acc: 0.6574 - val_loss: 1.2611 - val_acc: 0.5648
Epoch 13/50
 - 17s - loss: 0.9243 - acc: 0.6700 - val_loss: 1.4202 - val_acc: 0.5252
Epoch 14/50
 - 17s - loss: 0.9006 - acc: 0.6777 - val_loss: 1.1908 - val_acc: 0.5996
Epoch 15/50
 - 17s - loss: 0.8754 - acc: 0.6895 - val_loss: 1.5534 - val_acc: 0.5042
Epoch 16/50
 - 17s - loss: 0.8522 - acc: 0.6959 - val_loss: 1.1217 - val_acc: 0.6064
Epoch 17/50
 - 17s - loss: 0.8294 - acc: 0.7042 - val_loss: 1.2281 - val_acc: 0.5826
Epoch 18/50
 - 17s - loss: 0.8109 - acc: 0.7121 - val_loss: 1.1466 - val_acc: 0.6032
Epoch 19/50
 - 17s - loss: 0.7975 - acc: 0.7169 - val_loss: 1.0828 - val_acc: 0.6218
Epoch 20/50
 - 17s - loss: 0.7758 - acc: 0.7235 - val_loss: 1.1506 - val_acc: 0.6068
Epoch 21/50
 - 17s - loss: 0.7587 - acc: 0.7291 - val_loss: 0.9676 - val_acc: 0.6636
Epoch 22/50
 - 17s - loss: 0.7404 - acc: 0.7382 - val_loss: 0.9936 - val_acc: 0.6570
Epoch 23/50
 - 17s - loss: 0.7318 - acc: 0.7412 - val_loss: 1.0243 - val_acc: 0.6446
Epoch 24/50
 - 17s - loss: 0.7122 - acc: 0.7454 - val_loss: 0.9479 - val_acc: 0.6732
Epoch 25/50
 - 17s - loss: 0.7024 - acc: 0.7498 - val_loss: 0.9993 - val_acc: 0.6592
Epoch 26/50
 - 17s - loss: 0.6860 - acc: 0.7544 - val_loss: 0.9397 - val_acc: 0.6808
Epoch 27/50
 - 17s - loss: 0.6702 - acc: 0.7598 - val_loss: 0.8354 - val_acc: 0.7192
Epoch 28/50
 - 17s - loss: 0.6603 - acc: 0.7666 - val_loss: 1.4713 - val_acc: 0.5562
Epoch 29/50
 - 17s - loss: 0.6522 - acc: 0.7697 - val_loss: 0.8584 - val_acc: 0.7102
Epoch 30/50
 - 17s - loss: 0.6346 - acc: 0.7751 - val_loss: 0.9611 - val_acc: 0.6736
Epoch 31/50
 - 17s - loss: 0.6273 - acc: 0.7772 - val_loss: 0.9413 - val_acc: 0.6854
Epoch 32/50
 - 17s - loss: 0.6146 - acc: 0.7812 - val_loss: 0.8481 - val_acc: 0.7032
Epoch 33/50
 - 17s - loss: 0.6036 - acc: 0.7861 - val_loss: 0.9385 - val_acc: 0.6880
Epoch 34/50
 - 17s - loss: 0.5991 - acc: 0.7885 - val_loss: 0.8588 - val_acc: 0.7150
Epoch 35/50
 - 17s - loss: 0.5828 - acc: 0.7935 - val_loss: 0.8710 - val_acc: 0.7156
Epoch 36/50
 - 17s - loss: 0.5739 - acc: 0.7963 - val_loss: 1.0373 - val_acc: 0.6692
Epoch 37/50
 - 17s - loss: 0.5649 - acc: 0.8010 - val_loss: 0.8259 - val_acc: 0.7242
Epoch 38/50
 - 17s - loss: 0.5559 - acc: 0.8040 - val_loss: 0.8385 - val_acc: 0.7240
Epoch 39/50
 - 17s - loss: 0.5486 - acc: 0.8060 - val_loss: 0.9017 - val_acc: 0.7042
Epoch 40/50
 - 17s - loss: 0.5396 - acc: 0.8087 - val_loss: 1.1981 - val_acc: 0.6266
Epoch 41/50
 - 17s - loss: 0.5275 - acc: 0.8124 - val_loss: 0.8802 - val_acc: 0.7110
Epoch 42/50
 - 17s - loss: 0.5206 - acc: 0.8172 - val_loss: 0.9053 - val_acc: 0.7070
Epoch 43/50
 - 17s - loss: 0.5100 - acc: 0.8188 - val_loss: 0.8450 - val_acc: 0.7238
Epoch 44/50
 - 17s - loss: 0.5041 - acc: 0.8218 - val_loss: 0.8559 - val_acc: 0.7318
Epoch 45/50
 - 17s - loss: 0.4980 - acc: 0.8255 - val_loss: 0.8584 - val_acc: 0.7174
Epoch 46/50
 - 17s - loss: 0.4854 - acc: 0.8275 - val_loss: 0.8926 - val_acc: 0.7184
Epoch 47/50
 - 17s - loss: 0.4804 - acc: 0.8304 - val_loss: 0.9522 - val_acc: 0.6906
Epoch 48/50
 - 17s - loss: 0.4724 - acc: 0.8334 - val_loss: 0.7765 - val_acc: 0.7512
Epoch 49/50
 - 17s - loss: 0.4670 - acc: 0.8339 - val_loss: 0.8568 - val_acc: 0.7282
Epoch 50/50
 - 17s - loss: 0.4612 - acc: 0.8355 - val_loss: 0.8393 - val_acc: 0.7354
865.7029066085815
--------
{'val_loss': [1.8860879127502441, 2.0258747192382813, 2.30320452041626, 2.3936835037231443, 1.6139022766113282, 1.8559204231262207, 1.3325716758728028, 1.3744422149658204, 1.3951737075805664, 1.1833858806610107, 1.4883689720153808, 1.2610881614685059, 1.4202262199401856, 1.1908078441619874, 1.5533728130340576, 1.1217081398010254, 1.2280996131896973, 1.1466105422973634, 1.082793330001831, 1.150606876373291, 0.9675869659423828, 0.9936048460006713, 1.0243430559158324, 0.947874817276001, 0.9993253103256226, 0.9396674476623535, 0.8353645391464234, 1.4713117134094238, 0.8583705059051514, 0.9611056756973266, 0.9413054643630981, 0.8481438417434692, 0.9385309936523437, 0.8588067407608032, 0.8709685194015503, 1.0372986177444459, 0.8259399570465088, 0.8385479305267334, 0.901725499343872, 1.1980891441345214, 0.8801684093475342, 0.9052679012298585, 0.8450326286315918, 0.8558706539154053, 0.8584461025238037, 0.8926303533554077, 0.9521797477722168, 0.776528016090393, 0.8568195659637451, 0.8392688762664795], 'val_acc': [0.3136, 0.3188, 0.2848, 0.3192, 0.4562, 0.4318, 0.53, 0.5216, 0.5208, 0.5848, 0.5078, 0.5648, 0.5252, 0.5996, 0.5042, 0.6064, 0.5826, 0.6032, 0.6218, 0.6068, 0.6636, 0.657, 0.6446, 0.6732, 0.6592, 0.6808, 0.7192, 0.5562, 0.7102, 0.6736, 0.6854, 0.7032, 0.688, 0.715, 0.7156, 0.6692, 0.7242, 0.724, 0.7042, 0.6266, 0.711, 0.707, 0.7238, 0.7318, 0.7174, 0.7184, 0.6906, 0.7512, 0.7282, 0.7354], 'loss': [2.226588286421034, 1.539850215933058, 1.4068804447386, 1.319624913597107, 1.2488030686484444, 1.1907695188946195, 1.1388154457622104, 1.0903783969667222, 1.053329780069987, 1.017346155304379, 0.988026988389757, 0.9507244642681546, 0.9242862996525235, 0.9005695898585849, 0.875355642191569, 0.852193333668179, 0.8294235168880887, 0.8109177257537842, 0.7974800837516784, 0.7757644112375047, 0.7587258016268412, 0.7403743548499213, 0.7318073808140225, 0.7122117196083069, 0.7023521829711067, 0.6859967346615261, 0.6701625649982028, 0.6603299677318997, 0.6522080336358812, 0.6346079123497009, 0.6273080029699537, 0.6145945012834337, 0.603633301003774, 0.5991374510871039, 0.5828333217832777, 0.5739011127471924, 0.5648686990631951, 0.5558801473087734, 0.5485645360946655, 0.5395838659710355, 0.5275260053316753, 0.5206485433684455, 0.510032330915663, 0.5041136735863155, 0.4980331286218431, 0.4854026103125678, 0.48042737008200753, 0.4724024902502696, 0.466995949406094, 0.46123629270659555], 'acc': [0.3131333333545261, 0.43488888884650334, 0.488, 0.5228666666984558, 0.5493111110899184, 0.5714444444020589, 0.5923333332909478, 0.609711111079322, 0.6231111110687256, 0.6365777778095669, 0.6443777777671814, 0.6574444444656372, 0.6699777777989705, 0.6776888889312744, 0.6895111111217075, 0.6959111110687256, 0.7042222221798367, 0.7120666666666666, 0.7169111111005148, 0.7235333332909478, 0.7291111110899183, 0.7382444444762336, 0.7411555555873447, 0.7453777777353923, 0.7497555555343628, 0.7544000000423855, 0.7597555555767483, 0.7665777777883741, 0.7697333332909478, 0.7751111111217075, 0.7772444444232517, 0.7811777778201633, 0.7860888888888888, 0.7884666666666666, 0.7935333333545261, 0.7962888888676961, 0.8009555555979411, 0.803977777756585, 0.8059555555873447, 0.8087111111111112, 0.8123777778095669, 0.817244444433848, 0.8188, 0.8218222222116258, 0.8254888889312744, 0.8274888888994852, 0.8304222222328186, 0.8333555555555555, 0.8338888889312744, 0.8355111110687256]}
===Final Test Score===
Test loss: 0.7240570082187653
Test accuracy: 0.7773
